{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notas TFM\n",
    "\n",
    "# Tokenización"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['En',\n",
       " '1884,',\n",
       " 'con',\n",
       " 'treinta',\n",
       " 'y',\n",
       " 'dos',\n",
       " 'años,',\n",
       " 'Santiago',\n",
       " 'Ramón',\n",
       " 'y',\n",
       " 'Cajal',\n",
       " 'se',\n",
       " 'trasladó',\n",
       " 'a',\n",
       " 'Valencia',\n",
       " 'a',\n",
       " 'ocupar',\n",
       " 'su',\n",
       " 'cátedra.']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oracion = \"En 1884, con treinta y dos años, Santiago Ramón y Cajal se trasladó a Valencia a ocupar su cátedra.\"\n",
    "oracion.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1884,, Cajal, En, Ramón, Santiago, Valencia, a, años,, con, cátedra., dos, ocupar, se, su, trasladó, treinta, y'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "token_secuencia = str.split(oracion)\n",
    "vocab = sorted(set(token_secuencia))\n",
    "', '.join(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1884, Cajal En Ramón Santiago Valencia a años, con cátedra. dos ocupar se su trasladó treinta y'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_tokens = len(token_secuencia)\n",
    "tam_vocab = len(vocab)\n",
    "vectores_onehot = np.zeros((num_tokens, tam_vocab), int)\n",
    "for i, plb in enumerate(token_secuencia):\n",
    "    vectores_onehot[i, vocab.index(plb)] = 1\n",
    "' '.join(vocab)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1884,</th>\n",
       "      <th>Cajal</th>\n",
       "      <th>En</th>\n",
       "      <th>Ramón</th>\n",
       "      <th>Santiago</th>\n",
       "      <th>Valencia</th>\n",
       "      <th>a</th>\n",
       "      <th>años,</th>\n",
       "      <th>con</th>\n",
       "      <th>cátedra.</th>\n",
       "      <th>dos</th>\n",
       "      <th>ocupar</th>\n",
       "      <th>se</th>\n",
       "      <th>su</th>\n",
       "      <th>trasladó</th>\n",
       "      <th>treinta</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    1884,  Cajal  En  Ramón  Santiago  Valencia  a  años,  con  cátedra.  dos  \\\n",
       "0       0      0   1      0         0         0  0      0    0         0    0   \n",
       "1       1      0   0      0         0         0  0      0    0         0    0   \n",
       "2       0      0   0      0         0         0  0      0    1         0    0   \n",
       "3       0      0   0      0         0         0  0      0    0         0    0   \n",
       "4       0      0   0      0         0         0  0      0    0         0    0   \n",
       "5       0      0   0      0         0         0  0      0    0         0    1   \n",
       "6       0      0   0      0         0         0  0      1    0         0    0   \n",
       "7       0      0   0      0         1         0  0      0    0         0    0   \n",
       "8       0      0   0      1         0         0  0      0    0         0    0   \n",
       "9       0      0   0      0         0         0  0      0    0         0    0   \n",
       "10      0      1   0      0         0         0  0      0    0         0    0   \n",
       "11      0      0   0      0         0         0  0      0    0         0    0   \n",
       "12      0      0   0      0         0         0  0      0    0         0    0   \n",
       "13      0      0   0      0         0         0  1      0    0         0    0   \n",
       "14      0      0   0      0         0         1  0      0    0         0    0   \n",
       "15      0      0   0      0         0         0  1      0    0         0    0   \n",
       "16      0      0   0      0         0         0  0      0    0         0    0   \n",
       "17      0      0   0      0         0         0  0      0    0         0    0   \n",
       "18      0      0   0      0         0         0  0      0    0         1    0   \n",
       "\n",
       "    ocupar  se  su  trasladó  treinta  y  \n",
       "0        0   0   0         0        0  0  \n",
       "1        0   0   0         0        0  0  \n",
       "2        0   0   0         0        0  0  \n",
       "3        0   0   0         0        1  0  \n",
       "4        0   0   0         0        0  1  \n",
       "5        0   0   0         0        0  0  \n",
       "6        0   0   0         0        0  0  \n",
       "7        0   0   0         0        0  0  \n",
       "8        0   0   0         0        0  0  \n",
       "9        0   0   0         0        0  1  \n",
       "10       0   0   0         0        0  0  \n",
       "11       0   1   0         0        0  0  \n",
       "12       0   0   0         1        0  0  \n",
       "13       0   0   0         0        0  0  \n",
       "14       0   0   0         0        0  0  \n",
       "15       0   0   0         0        0  0  \n",
       "16       1   0   0         0        0  0  \n",
       "17       0   0   1         0        0  0  \n",
       "18       0   0   0         0        0  0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(vectores_onehot, columns=vocab)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En esta presentación `df` muestra un documento de una sola oración en la que cada fila es un vector de una sola palabra. A esto corresponde un vector _onehot_: `1` significa que la palabra está activada, `0` que no. \n",
    "\n",
    "Mediante este tipo de tablas es difícil que se pierda mucha información.\n",
    "\n",
    "Este es el punto de partida de métodos como redes neuronales, modelos lingüísticos de secuencia a secuencia y generadores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bolsas de palabras\n",
    "\n",
    "Para tener un control sobre la frecuencia con la que aparece cada palabra en un documento se crea un saco de palabras ( _bag of words_ )."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('1884,', 1),\n",
       " ('Cajal', 1),\n",
       " ('En', 1),\n",
       " ('Ramón', 1),\n",
       " ('Santiago', 1),\n",
       " ('Valencia', 1),\n",
       " ('a', 1),\n",
       " ('años,', 1),\n",
       " ('con', 1),\n",
       " ('cátedra.', 1),\n",
       " ('dos', 1),\n",
       " ('ocupar', 1),\n",
       " ('se', 1),\n",
       " ('su', 1),\n",
       " ('trasladó', 1),\n",
       " ('treinta', 1),\n",
       " ('y', 1)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sdp_oracion = {}\n",
    "for token in oracion.split():\n",
    "    sdp_oracion[token] = 1\n",
    "sorted(sdp_oracion.items())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bajo este principio se pueden agregar más oraciones para hacer más grande el documento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>En</th>\n",
       "      <th>1884,</th>\n",
       "      <th>con</th>\n",
       "      <th>treinta</th>\n",
       "      <th>y</th>\n",
       "      <th>dos</th>\n",
       "      <th>años,</th>\n",
       "      <th>Santiago</th>\n",
       "      <th>Ramón</th>\n",
       "      <th>Cajal</th>\n",
       "      <th>...</th>\n",
       "      <th>tenía</th>\n",
       "      <th>tres:</th>\n",
       "      <th>los</th>\n",
       "      <th>mayores</th>\n",
       "      <th>eran</th>\n",
       "      <th>muchacha,</th>\n",
       "      <th>Fe,</th>\n",
       "      <th>un</th>\n",
       "      <th>chico,</th>\n",
       "      <th>Santiago.</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>orac0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>orac1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>orac2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>orac3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 62 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       En  1884,  con  treinta  y  dos  años,  Santiago  Ramón  Cajal  ...  \\\n",
       "orac0   1      1    1        1  1    1      1         1      1      1  ...   \n",
       "orac1   0      0    0        0  0    0      0         0      0      0  ...   \n",
       "orac2   0      0    0        0  0    0      0         0      0      0  ...   \n",
       "orac3   0      0    0        0  1    1      0         0      0      0  ...   \n",
       "\n",
       "       tenía  tres:  los  mayores  eran  muchacha,  Fe,  un  chico,  Santiago.  \n",
       "orac0      0      0    0        0     0          0    0   0       0          0  \n",
       "orac1      0      0    0        0     0          0    0   0       0          0  \n",
       "orac2      0      0    0        0     0          0    0   0       0          0  \n",
       "orac3      1      1    1        1     1          1    1   1       1          1  \n",
       "\n",
       "[4 rows x 62 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oraciones = \"\"\"En 1884, con treinta y dos años, Santiago Ramón y Cajal se trasladó a Valencia a ocupar su cátedra.\\n\"\"\"\n",
    "oraciones += \"\"\"Llegó en enero y, junto a su familia, se hospedó provisionalmente en una fonda situada en la plaza del Mercado, cerca de la vieja Lonja de la Seda.\\n\"\"\"\n",
    "oraciones += \"\"\"Pronto encontró una casita en la calle dude las Avellanas, donde pocos días después nacía su hija Paula.\\n\"\"\"\n",
    "oraciones += \"\"\"Ahora tenía tres: los dos mayores eran una muchacha, Fe, y un chico, Santiago.\"\"\"\n",
    "corpus = {}\n",
    "for i, orac in enumerate(oraciones.split('\\n')):\n",
    "    corpus['orac{}'.format(i)] = dict((tok, 1) for tok in orac.split())\n",
    "df = pd.DataFrame.from_records(corpus).fillna(0).astype(int).T\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Producto escalar\n",
    "\n",
    "Transformando documentos en tablas se pueden realizar productos escalares.\n",
    "\n",
    "Mediante el método `.dot` es posible saber cuántas palabras se traslapan entre las distintas oraciones. Se podría decir que esta es una medida de similaridad. En este caso, se contrasta contra la primera oración `orac0`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.T\n",
    "df.orac0.dot(df.orac1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.orac0.dot(df.orac2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.orac0.dot(df.orac3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sabemos que tanto `orac0` como `orac3` tienen a la palabra `Santiago`, pero el código que hemos puesto hasta ahora no lo detecta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('y', 1), ('dos', 1)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(k, v) for (k, v) in (df.orac0 & df.orac3).items() if v]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esto sucede porque sin una orden explícita el programa considera como palabras distintas a `Santiago` y `Santiago.`. Para solucionar este problema, se utiliza una técnica llamada **expresiones regulares** ( _regular expresions_ o _regex_ ):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['En',\n",
       " '1884',\n",
       " 'con',\n",
       " 'treinta',\n",
       " 'y',\n",
       " 'dos',\n",
       " 'años',\n",
       " 'Santiago',\n",
       " 'Ramón',\n",
       " 'y',\n",
       " 'Cajal',\n",
       " 'se',\n",
       " 'trasladó',\n",
       " 'a',\n",
       " 'Valencia',\n",
       " 'a',\n",
       " 'ocupar',\n",
       " 'su',\n",
       " 'cátedra']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "patron = re.compile(r\"([-\\s.,;!?])+\")\n",
    "tokens = patron.split(oracion)\n",
    "tokens = [x for x in tokens if x and x not in '- \\t\\n.,;!?']\n",
    "tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Existen varios módulos de Python que ayudan a realizar esta tarea, como lo son:\n",
    "\n",
    "* NLTK: más popular para procesamiento de lenguaje natural.\n",
    "* spaCy: preciso, flexible, rápido y nativo de Python.\n",
    "* Stanford CoreNLP: más preciso, menos flexible, rápido y basado en Java 8.\n",
    "\n",
    "Para este ejemplo, utilizaremos `TreebankWordTokenizer` para realizar las filtraciones sin que tengamos preocuparnos por ellas. Además, esta función permite conservar signos de puntuación que podrían ser relevantes en algún momento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['En',\n",
       " '1884',\n",
       " ',',\n",
       " 'con',\n",
       " 'treinta',\n",
       " 'y',\n",
       " 'dos',\n",
       " 'años',\n",
       " ',',\n",
       " 'Santiago',\n",
       " 'Ramón',\n",
       " 'y',\n",
       " 'Cajal',\n",
       " 'se',\n",
       " 'trasladó',\n",
       " 'a',\n",
       " 'Valencia',\n",
       " 'a',\n",
       " 'ocupar',\n",
       " 'su',\n",
       " 'cátedra',\n",
       " '.']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import TreebankWordTokenizer\n",
    "tokenizador = TreebankWordTokenizer()\n",
    "tokenizador.tokenize(oracion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## N-grams\n",
    "\n",
    "Detectar una palabra muchas veces no es suficiente porque el sentido de ese token depende de sus vecinos, como lo es \"Santiago Ramón y Cajal\". Para abordar esta situación, se determinan los *n_grams*, cuya *n* corresponde al número de vecinos contiguos que se extraen de las oraciones. La tokenización que hicimos previamente utiliza `1-gram`. Para el nombre propio de Cajal, utilizaríamos `4-gram`, como se ejemplifica a continuación:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['En 1884 con',\n",
       " '1884 con treinta',\n",
       " 'con treinta y',\n",
       " 'treinta y dos',\n",
       " 'y dos años',\n",
       " 'dos años Santiago',\n",
       " 'años Santiago Ramón',\n",
       " 'Santiago Ramón y',\n",
       " 'Ramón y Cajal',\n",
       " 'y Cajal se',\n",
       " 'Cajal se trasladó',\n",
       " 'se trasladó a',\n",
       " 'trasladó a Valencia',\n",
       " 'a Valencia a',\n",
       " 'Valencia a ocupar',\n",
       " 'a ocupar su',\n",
       " 'ocupar su cátedra']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.util import ngrams\n",
    "\n",
    "tres_grams = list(ngrams(tokens, 3))\n",
    "[\" \".join(x) for x in tres_grams]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['En 1884 con treinta',\n",
       " '1884 con treinta y',\n",
       " 'con treinta y dos',\n",
       " 'treinta y dos años',\n",
       " 'y dos años Santiago',\n",
       " 'dos años Santiago Ramón',\n",
       " 'años Santiago Ramón y',\n",
       " 'Santiago Ramón y Cajal',\n",
       " 'Ramón y Cajal se',\n",
       " 'y Cajal se trasladó',\n",
       " 'Cajal se trasladó a',\n",
       " 'se trasladó a Valencia',\n",
       " 'trasladó a Valencia a',\n",
       " 'a Valencia a ocupar',\n",
       " 'Valencia a ocupar su',\n",
       " 'a ocupar su cátedra']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cuatro_grams = list(ngrams(tokens, 4))\n",
    "[\" \".join(x) for x in cuatro_grams]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El problema de esta aproximación es que en un documento, casos como \"Santiago Ramón y Cajal\" o \"treinta y dos\" ocurrirán rara vez. Eso implica que difícilmente existirá una correlación con otras palabras que permita identificar un tema contenido en documentos. Adicionalmente, cada *n-gram* aumenta exponencialmente el tamaño del documento, por lo que no es viable.\n",
    "\n",
    "Por otra parte, también se encuentran palabras que no aportan mayor información, como son los artículos y preposiciones. llamadas \"palabras vacías\" ( *stop_words* ). Existen razones computacionales para quitarlas, aunque presentan sus propios inconvenientes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['de', 'la', 'que', 'el', 'en', 'y', 'a']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "pal_vacias = stopwords.words('spanish')\n",
    "pal_vacias[:7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['niño', 'salió', 'jugar']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = ['el', 'niño', 'salió', 'a', 'jugar']\n",
    "tokens_sin_pal_vacias = [x for x in tokens if x not in pal_vacias]\n",
    "tokens_sin_pal_vacias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Raíces y lemas\n",
    "\n",
    "_pendiente_ ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vectores TF-IDF\n",
    "\n",
    "El nombre que se le da a las tablas creadas con el saco de palabras se les denomina **TF-IDF** o frecuencia de términos por la inversa de la frecuencia en el documento ( _Term Frequency times inverse document frequency_ ).\n",
    "\n",
    "### Frecuencias\n",
    "\n",
    "Primero se obtienen las frecuencias.\n",
    "\n",
    "### Ejemplo con artículo\n",
    "\n",
    "Se utiliza como ejemplo el artículo de wikipedia del rehilete o molinillo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "rehilete = \"\"\"\n",
    "El molinillo, molinete, remolino, renglete, rehilete o reguilete es una especie de juguete compuesto por una varilla de madera a la que se clava, en la parte superior, una figura de aspas de molinillo construida con papel celofán o cartulina, habitualmente de colores llamativos. Con el viento, las aspas giran y crean efectos de color.\n",
    "\n",
    "Se le llama de muy diversas formas según los países; en España es más conocido como «molinillo»; en México o Perú, «rehilete», en Guatemala y el resto de Centroamérica y también en Cuba se le conoce como «reguilete», en Colombia se conoce como ringlete o renglete. En Chile se le conoce como «remolino».\n",
    "\n",
    "María Moliner cita los siguientes sinónimos: gallo, molinete, rehilandera, rodachina, rongigata, ventolera y voladera.\n",
    "\n",
    "Rehilete, a veces pronunciado reguilete o rejilete, proviene del verbo rehilar. Proviene de la idea del movimiento rotatorio y tembloroso del huso y de la hebra en el acto de hilar. Se usaba en el antiguo castellano o en Segovia con el sentido de temblor y posiblemente se deriva del godo \"reiro\" con significado de temblor o tremor. Diccionario etimológico de la lengua castellana. Dr. D. Pedro Felipe Monlau. 1881.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'el': 6,\n",
       "         'molinillo': 3,\n",
       "         ',': 18,\n",
       "         'molinete': 2,\n",
       "         'remolino': 2,\n",
       "         'renglete': 1,\n",
       "         'rehilete': 3,\n",
       "         'o': 7,\n",
       "         'reguilete': 3,\n",
       "         'es': 2,\n",
       "         'una': 3,\n",
       "         'especie': 1,\n",
       "         'de': 14,\n",
       "         'juguete': 1,\n",
       "         'compuesto': 1,\n",
       "         'por': 1,\n",
       "         'varilla': 1,\n",
       "         'madera': 1,\n",
       "         'a': 2,\n",
       "         'la': 5,\n",
       "         'que': 1,\n",
       "         'se': 7,\n",
       "         'clava': 1,\n",
       "         'en': 10,\n",
       "         'parte': 1,\n",
       "         'superior': 1,\n",
       "         'figura': 1,\n",
       "         'aspas': 2,\n",
       "         'construida': 1,\n",
       "         'con': 4,\n",
       "         'papel': 1,\n",
       "         'celofán': 1,\n",
       "         'cartulina': 1,\n",
       "         'habitualmente': 1,\n",
       "         'colores': 1,\n",
       "         'llamativos.': 1,\n",
       "         'viento': 1,\n",
       "         'las': 1,\n",
       "         'giran': 1,\n",
       "         'y': 7,\n",
       "         'crean': 1,\n",
       "         'efectos': 1,\n",
       "         'color.': 1,\n",
       "         'le': 3,\n",
       "         'llama': 1,\n",
       "         'muy': 1,\n",
       "         'diversas': 1,\n",
       "         'formas': 1,\n",
       "         'según': 1,\n",
       "         'los': 2,\n",
       "         'países': 1,\n",
       "         ';': 2,\n",
       "         'españa': 1,\n",
       "         'más': 1,\n",
       "         'conocido': 1,\n",
       "         'como': 4,\n",
       "         '«': 4,\n",
       "         '»': 4,\n",
       "         'méxico': 1,\n",
       "         'perú': 1,\n",
       "         'guatemala': 1,\n",
       "         'resto': 1,\n",
       "         'centroamérica': 1,\n",
       "         'también': 1,\n",
       "         'cuba': 1,\n",
       "         'conoce': 3,\n",
       "         'colombia': 1,\n",
       "         'ringlete': 1,\n",
       "         'renglete.': 1,\n",
       "         'chile': 1,\n",
       "         '.': 2,\n",
       "         'maría': 1,\n",
       "         'moliner': 1,\n",
       "         'cita': 1,\n",
       "         'siguientes': 1,\n",
       "         'sinónimos': 1,\n",
       "         ':': 1,\n",
       "         'gallo': 1,\n",
       "         'rehilandera': 1,\n",
       "         'rodachina': 1,\n",
       "         'rongigata': 1,\n",
       "         'ventolera': 1,\n",
       "         'voladera.': 1,\n",
       "         'veces': 1,\n",
       "         'pronunciado': 1,\n",
       "         'rejilete': 1,\n",
       "         'proviene': 2,\n",
       "         'del': 4,\n",
       "         'verbo': 1,\n",
       "         'rehilar.': 1,\n",
       "         'idea': 1,\n",
       "         'movimiento': 1,\n",
       "         'rotatorio': 1,\n",
       "         'tembloroso': 1,\n",
       "         'huso': 1,\n",
       "         'hebra': 1,\n",
       "         'acto': 1,\n",
       "         'hilar.': 1,\n",
       "         'usaba': 1,\n",
       "         'antiguo': 1,\n",
       "         'castellano': 1,\n",
       "         'segovia': 1,\n",
       "         'sentido': 1,\n",
       "         'temblor': 2,\n",
       "         'posiblemente': 1,\n",
       "         'deriva': 1,\n",
       "         'godo': 1,\n",
       "         '``': 1,\n",
       "         'reiro': 1,\n",
       "         \"''\": 1,\n",
       "         'significado': 1,\n",
       "         'tremor.': 1,\n",
       "         'diccionario': 1,\n",
       "         'etimológico': 1,\n",
       "         'lengua': 1,\n",
       "         'castellana.': 1,\n",
       "         'dr.': 1,\n",
       "         'd.': 1,\n",
       "         'pedro': 1,\n",
       "         'felipe': 1,\n",
       "         'monlau.': 1,\n",
       "         '1881': 1})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "from nltk.tokenize import TreebankWordTokenizer\n",
    "tokenizador = TreebankWordTokenizer()\n",
    "tokens = tokenizador.tokenize(rehilete.lower())\n",
    "token_contador = Counter(tokens)\n",
    "token_contador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'molinillo': 3,\n",
       "         ',': 18,\n",
       "         'molinete': 2,\n",
       "         'remolino': 2,\n",
       "         'renglete': 1,\n",
       "         'rehilete': 3,\n",
       "         'reguilete': 3,\n",
       "         'especie': 1,\n",
       "         'juguete': 1,\n",
       "         'compuesto': 1,\n",
       "         'varilla': 1,\n",
       "         'madera': 1,\n",
       "         'clava': 1,\n",
       "         'parte': 1,\n",
       "         'superior': 1,\n",
       "         'figura': 1,\n",
       "         'aspas': 2,\n",
       "         'construida': 1,\n",
       "         'papel': 1,\n",
       "         'celofán': 1,\n",
       "         'cartulina': 1,\n",
       "         'habitualmente': 1,\n",
       "         'colores': 1,\n",
       "         'llamativos.': 1,\n",
       "         'viento': 1,\n",
       "         'giran': 1,\n",
       "         'crean': 1,\n",
       "         'efectos': 1,\n",
       "         'color.': 1,\n",
       "         'llama': 1,\n",
       "         'diversas': 1,\n",
       "         'formas': 1,\n",
       "         'según': 1,\n",
       "         'países': 1,\n",
       "         ';': 2,\n",
       "         'españa': 1,\n",
       "         'conocido': 1,\n",
       "         '«': 4,\n",
       "         '»': 4,\n",
       "         'méxico': 1,\n",
       "         'perú': 1,\n",
       "         'guatemala': 1,\n",
       "         'resto': 1,\n",
       "         'centroamérica': 1,\n",
       "         'cuba': 1,\n",
       "         'conoce': 3,\n",
       "         'colombia': 1,\n",
       "         'ringlete': 1,\n",
       "         'renglete.': 1,\n",
       "         'chile': 1,\n",
       "         '.': 2,\n",
       "         'maría': 1,\n",
       "         'moliner': 1,\n",
       "         'cita': 1,\n",
       "         'siguientes': 1,\n",
       "         'sinónimos': 1,\n",
       "         ':': 1,\n",
       "         'gallo': 1,\n",
       "         'rehilandera': 1,\n",
       "         'rodachina': 1,\n",
       "         'rongigata': 1,\n",
       "         'ventolera': 1,\n",
       "         'voladera.': 1,\n",
       "         'veces': 1,\n",
       "         'pronunciado': 1,\n",
       "         'rejilete': 1,\n",
       "         'proviene': 2,\n",
       "         'verbo': 1,\n",
       "         'rehilar.': 1,\n",
       "         'idea': 1,\n",
       "         'movimiento': 1,\n",
       "         'rotatorio': 1,\n",
       "         'tembloroso': 1,\n",
       "         'huso': 1,\n",
       "         'hebra': 1,\n",
       "         'acto': 1,\n",
       "         'hilar.': 1,\n",
       "         'usaba': 1,\n",
       "         'antiguo': 1,\n",
       "         'castellano': 1,\n",
       "         'segovia': 1,\n",
       "         'temblor': 2,\n",
       "         'posiblemente': 1,\n",
       "         'deriva': 1,\n",
       "         'godo': 1,\n",
       "         '``': 1,\n",
       "         'reiro': 1,\n",
       "         \"''\": 1,\n",
       "         'significado': 1,\n",
       "         'tremor.': 1,\n",
       "         'diccionario': 1,\n",
       "         'etimológico': 1,\n",
       "         'lengua': 1,\n",
       "         'castellana.': 1,\n",
       "         'dr.': 1,\n",
       "         'd.': 1,\n",
       "         'pedro': 1,\n",
       "         'felipe': 1,\n",
       "         'monlau.': 1,\n",
       "         '1881': 1})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "pal_vacias = stopwords.words('spanish')\n",
    "\n",
    "tokens = [x for x in tokens if x not in pal_vacias]\n",
    "rehilete_contador = Counter(tokens)\n",
    "rehilete_contador"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorizando\n",
    "\n",
    "Luego de obtener las frecuencias, se convierte el resultado en vectores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.13043478260869565,\n",
       " 0.028985507246376812,\n",
       " 0.028985507246376812,\n",
       " 0.021739130434782608,\n",
       " 0.021739130434782608,\n",
       " 0.021739130434782608,\n",
       " 0.021739130434782608,\n",
       " 0.014492753623188406,\n",
       " 0.014492753623188406,\n",
       " 0.014492753623188406]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_documento = []\n",
    "extens_doc = len(tokens)\n",
    "\n",
    "for cve, valor in rehilete_contador.most_common():\n",
    "    vector_documento.append(valor / extens_doc)\n",
    "vector_documento[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Espacios vectoriales\n",
    "\n",
    "### La ley de Zipf\n",
    "\n",
    "### Estableciendo un modelo\n",
    "\n",
    "\n",
    "### Distancia por coseno\n",
    "\n",
    "# Análisis semántico latente\n",
    "\n",
    "## Descomposición en valores singulares\n",
    "\n",
    "## Análisis de componentes principales\n",
    "\n",
    "## Análisis discriminante lineal\n",
    "\n",
    "## Distribución de Dirichlet latente\n",
    "\n",
    "## Comparación de resultados\n",
    "\n",
    "# Redes neuronales\n",
    "\n",
    "## Aprendizaje profundo\n",
    "\n",
    "## Redes complejas\n",
    "\n",
    "## Propagación retroactiva\n",
    "\n",
    "## Secuencia a secuencia"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfm",
   "language": "python",
   "name": "tfm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
